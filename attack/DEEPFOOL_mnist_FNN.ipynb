{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "2.7.18-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 2.7.18 64-bit ('exp27': conda)",
   "display_name": "Python 2.7.18 64-bit ('exp27': conda)",
   "metadata": {
    "interpreter": {
     "hash": "94b498c9aad39d14fe2eef1427b4eed5fb73bba001ef4744562740919eaae58d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../code\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(28*28,1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(1024, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(1024, 10),\n",
    "            nn.Sigmoid()\n",
    "    )\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 28*28)\n",
    "        x = self.fc_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "pretrained_model=\"../../target/mnist/FNN.pt\"\n",
    "model.load_state_dict(torch.load(pretrained_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'DEEPFOOL'\n",
    "config = 'DEEPFOOL_mnist.json'\n",
    "target_model = model\n",
    "loss_func = None\n",
    "data_set = 'mnist'\n",
    "METHOD_dataset_NET = 'DEEPFOOL_mnist_FNN'\n",
    "choose = 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n",
      "-test set start-\n",
      "count:10000/10000,cost:0.030901s\n",
      "test set cost:298.29553008s\n",
      "saving...\n",
      "-complete-\n"
     ]
    }
   ],
   "source": [
    "gen.trod_attck(\n",
    "    method,\n",
    "    config,\n",
    "    target_model,\n",
    "    loss_func,\n",
    "    data_set,\n",
    "    METHOD_dataset_NET,\n",
    "    choose\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FNN, self).__init__()\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(28*28,1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(1024, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(4096, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(1024, 10),\n",
    "            nn.Sigmoid()\n",
    "    )\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), 28*28)\n",
    "        x = self.fc_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = FNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "test_model=\"../../target/mnist/FNN.pt\"\n",
    "t_model.load_state_dict(torch.load(test_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fooling_rate:96.780000%\n"
     ]
    }
   ],
   "source": [
    "# robustness_test(model, adv_sample_path, sample_num, sample_shape)\n",
    "tst.robustness_test(\n",
    "    model = t_model,\n",
    "    adv_sample_path = '../sample/DEEPFOOL_mnist_FNN/test',\n",
    "    sample_num = 10000,\n",
    "    sample_shape = [1,28,28]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, 5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(6, 16, 5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256, 120),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(120, 84),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(84, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "test_model=\"../../target/mnist/LeNet.pt\"\n",
    "t_model.load_state_dict(torch.load(test_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fooling_rate:40.280000%\n"
     ]
    }
   ],
   "source": [
    "# robustness_test(model, adv_sample_path, sample_num, sample_shape)\n",
    "tst.robustness_test(\n",
    "    model = t_model,\n",
    "    adv_sample_path = '../sample/DEEPFOOL_mnist_FNN/test',\n",
    "    sample_num = 10000,\n",
    "    sample_shape = [1,28,28]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(inchannel,outchannel,kernel_size=3,padding=1,stride=stride,bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, padding=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.right = nn.Sequential()\n",
    "        \n",
    "        if(inchannel != outchannel):\n",
    "            self.right = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=3, padding=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(outchannel),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        out += self.right(x)\n",
    "        out =F.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResidualBlock, num_classes=10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1,64,kernel_size=3,stride=1,padding=1,bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.layer1 = self.make_layer(ResidualBlock, 64,  2, stride=1)\n",
    "        self.layer2 = self.make_layer(ResidualBlock, 128, 2, stride=1)\n",
    "        self.conv2 = nn.Conv2d(128,128,3,stride=2)\n",
    "        self.layer3 = self.make_layer(ResidualBlock, 256, 2, stride=1)\n",
    "        self.conv3 = nn.Conv2d(256, 256, 3, stride=2)\n",
    "        #self.layer4 = self.make_layer(ResidualBlock, 512, 2, stride=1)\n",
    "        self.conv4 = nn.Conv2d(256,256,6)\n",
    "        self.fc = nn.Linear(256, num_classes)\n",
    "\n",
    "    def make_layer(self, block, channels, num_blocks, stride):\n",
    "        layer = []\n",
    "        for i in range(num_blocks):\n",
    "            layer.append(block(self.inchannel,channels,stride))\n",
    "            self.inchannel = channels\n",
    "        #\n",
    "        return nn.Sequential(*layer)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.conv3(out)\n",
    "        #out = self.layer4(out)\n",
    "        out = self.conv4(out)\n",
    "        #out = F.avg_pool2d(out,4)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "def ResNet18():\n",
    "    return ResNet(ResidualBlock)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = ResNet18()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "test_model=\"../../target/mnist/ResNet18.pt\"\n",
    "t_model.load_state_dict(torch.load(test_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fooling_rate:22.510000%\n"
     ]
    }
   ],
   "source": [
    "tst.robustness_test(\n",
    "    model = t_model,\n",
    "    adv_sample_path = '../sample/DEEPFOOL_mnist_FNN/test',\n",
    "    sample_num = 10000,\n",
    "    sample_shape = [1,28,28]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}